{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Optional, Literal\n",
    "from datetime import datetime\n",
    "from llama_index.core.query_pipeline import QueryPipeline as QP\n",
    "from llama_index.legacy.service_context import ServiceContext\n",
    "from llama_index.core import VectorStoreIndex, load_index_from_storage\n",
    "from sqlalchemy import text\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.storage import StorageContext\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "from llama_index.core.retrievers import SQLRetriever\n",
    "from typing import List\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "\n",
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    "    CustomQueryComponent,\n",
    ")\n",
    "from llama_index.core.workflow import Workflow\n",
    "from pyvis.network import Network\n",
    "from llama_index.core.retrievers import SQLRetriever\n",
    "from typing import List\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "\n",
    "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_TO_SQL_PROMPT\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.query_pipeline import FnComponent\n",
    "from llama_index.core.llms import ChatResponse\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# put data into sqlite db\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    ")\n",
    "import re\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import SQLDatabase, VectorStoreIndex\n",
    "\n",
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    "    CustomQueryComponent,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    step, \n",
    "    Context, \n",
    "    Workflow, \n",
    "    Event, \n",
    "    StartEvent, \n",
    "    StopEvent\n",
    ")\n",
    "#from llama_index.llms.anthropic import Anthropic\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from enum import Enum\n",
    "from typing import Optional, List, Callable, Tuple\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from colorama import Fore, Back, Style\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.llms.openai import OpenAI as OpenAIIndex\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = openai.OpenAI()\n",
    "MODEL = 'gpt-4o-2024-08-06'\n",
    "\n",
    "# Get the environment variables\n",
    "host = os.getenv('MYSQL_DB_HOST')\n",
    "user = os.getenv('MYSQL_DB_USER')\n",
    "password = os.getenv('MYSQL_DB_PASSWORD')\n",
    "database = os.getenv('MYSQL_SALES_DB_NAME')\n",
    "\n",
    "appsheet_app_id = os.getenv('APPSHEET_APP_ID')\n",
    "appsheet_api_key = os.getenv('APPSHEET_API_KEY')\n",
    "\n",
    "# Construct the connection string\n",
    "connection_string = f\"mysql+pymysql://{user}:{password}@{host}/{database}\"\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "metadata_obj = MetaData()\n",
    "sql_database = SQLDatabase(engine)\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "sql_retriever = SQLRetriever(sql_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTEXTO EN VIVO - Data indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing rows in table: CATEGORÍAS CAJA\n",
      "index already exists\n",
      "Indexing rows in table: CATEGORÍAS PRODUCTOS\n",
      "index already exists\n",
      "Indexing rows in table: CLIENTES\n",
      "index already exists\n",
      "Indexing rows in table: COLORES\n",
      "index already exists\n",
      "Indexing rows in table: ESTADOS\n",
      "index already exists\n",
      "Indexing rows in table: IVA\n",
      "index already exists\n",
      "Indexing rows in table: MÉTODOS DE PAGO\n",
      "index already exists\n",
      "Indexing rows in table: PERSONAL\n",
      "index already exists\n",
      "Indexing rows in table: PRODUCTOS\n",
      "index already exists\n",
      "Indexing rows in table: PROVEEDORES\n",
      "index already exists\n"
     ]
    }
   ],
   "source": [
    "def index_all_tables(\n",
    "    sql_database: SQLDatabase, table_index_dir: str = \"./table_indices\"\n",
    ") -> Dict[str, VectorStoreIndex]:\n",
    "    \"\"\"Index all tables.\"\"\"\n",
    "\n",
    "    table_names = ['CATEGORÍAS CAJA', 'CATEGORÍAS PRODUCTOS', 'CLIENTES', 'COLORES', 'ESTADOS', 'IVA', 'MÉTODOS DE PAGO', 'PERSONAL', 'PRODUCTOS', 'PROVEEDORES']\n",
    "    # no indexd: CAJA, CHEQUES, PRODUCTOS PEDIDOS, STOCK, CUENTAS CORRIENTES, PEDIDOS, CONTROL DE PRECIOS\n",
    "\n",
    "    if not Path(table_index_dir).exists():\n",
    "        os.makedirs(table_index_dir)\n",
    "\n",
    "    vector_index_dict = {}\n",
    "    engine = sql_database.engine\n",
    "    for table_name in table_names: #sql_database.get_usable_table_names():\n",
    "        print(f\"Indexing rows in table: {table_name}\")\n",
    "\n",
    "        if not os.path.exists(f\"{table_index_dir}/{table_name}\"):\n",
    "            # get all rows from table\n",
    "            with engine.connect() as conn:\n",
    "\n",
    "                columns_query=(\n",
    "                    f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}'\"\n",
    "                    f\"AND TABLE_SCHEMA = '{database}'\"\n",
    "                )\n",
    "\n",
    "                cursor = conn.execute(text(columns_query))\n",
    "                result = cursor.fetchall()\n",
    "                columns = []\n",
    "                for column in result:\n",
    "                    columns.append(column[0]) # get the first and only element of the tuple (the name)\n",
    "\n",
    "                cursor = conn.execute(text(f'SELECT * FROM `{table_name}`'))\n",
    "                result = cursor.fetchall()\n",
    "                row_tups = []\n",
    "                for row in result:\n",
    "                    row_tups.append(tuple(row))\n",
    "                    #print(dict(zip(columns, row)))\n",
    "\n",
    "            # index each row, put into vector store index\n",
    "            # TODO: CHECK THIS LINE: metadata\n",
    "            nodes = [\n",
    "                TextNode(text=str(t), \n",
    "                         metadata=dict(zip(columns, \n",
    "                                           #check rows types\n",
    "                                           [str(value) if isinstance(value, datetime) else value \n",
    "                                            for value in t]\n",
    "                                           ))) \n",
    "                for t in row_tups]\n",
    "\n",
    "            # put into vector store index (use OpenAIEmbeddings by default)\n",
    "            index = VectorStoreIndex(nodes) #service_context=service_context\n",
    "\n",
    "            # save index\n",
    "            index.set_index_id(\"vector_index\")\n",
    "            index.storage_context.persist(f\"{table_index_dir}/{table_name}\")\n",
    "        else:\n",
    "            print('index already exists')\n",
    "            # rebuild storage context\n",
    "            storage_context = StorageContext.from_defaults(\n",
    "                persist_dir=f\"{table_index_dir}/{table_name}\"\n",
    "            )\n",
    "            # load index\n",
    "            index = load_index_from_storage(\n",
    "                storage_context, index_id=\"vector_index\") #service_context=service_context\n",
    "            \n",
    "        vector_index_dict[table_name] = index\n",
    "\n",
    "    return vector_index_dict\n",
    "\n",
    "vector_index_dict = index_all_tables(sql_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermediate steps testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(996778, 'Jorge Botta', 1112345689, 4513882, 'Oran 3196', None, None, None, None, None, None, None)\n",
      "{'ID': 996778, 'CLIENTE': 'Jorge Botta', 'TELEFONO': 1112345689, 'DNI/CUIT': 4513882, 'DIRECCION': 'Oran 3196', 'LIMITE_DE_SALDO': None, 'CUENTA_CORRIENTE': None, 'RESTO_DE_SALDO': None, 'IVA': None, 'IVA_MINIMO': None, 'LISTA_DE_PRECIOS': None, 'USUARIO': None}\n"
     ]
    }
   ],
   "source": [
    "test_retriever = vector_index_dict[\"CLIENTES\"].as_retriever(\n",
    "    similarity_top_k=1\n",
    ")\n",
    "nodes = test_retriever.retrieve(\"cliente\")\n",
    "print(nodes[0].get_content())\n",
    "print(nodes[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 1, 'PRODUCTO': 'RM X 30 KG LINEA NORT PREMIUM', 'CATEGORÍA': 'REVESTIMIENTO', 'PRECIO ESTANDAR S/IVA': 41400.0, 'PRECIO INTENSO S/IVA': 47035.0, 'IVA': '21', 'STOCK FÁBRICA': 284, 'VALOR STOCK': 11757600.0, 'VALOR STOCK TOTAL': 'VALOR TOTAL'}\n"
     ]
    }
   ],
   "source": [
    "test_retriever = vector_index_dict[\"PRODUCTOS\"].as_retriever(\n",
    "    similarity_top_k=1\n",
    ")\n",
    "nodes = test_retriever.retrieve(\"RM X 30 KG LINEA NORT PREMIUM\") #RM X 30 KG LINEA NORT PREMIUM\n",
    "#print(nodes[0].get_content(metadata_mode='all'))\n",
    "print(nodes[0].metadata)\n",
    "#response.source_nodes[0].node.metadata['file_name']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROMPTEO - Classes definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitializeEvent(Event):\n",
    "    pass\n",
    "\n",
    "class ConciergeEvent(Event):\n",
    "    request: Optional[str] = None\n",
    "    just_completed: Optional[str] = None\n",
    "    need_help: Optional[bool] = None\n",
    "\n",
    "class OrchestratorEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class OrderCreationEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class OrderUpdateEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class StockManagerEvent(Event):\n",
    "    request: str\n",
    "\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConciergeAgent():\n",
    "    name: str\n",
    "    parent: Workflow\n",
    "    tools: list[FunctionTool]\n",
    "    system_prompt: str\n",
    "    context: Context\n",
    "    current_event: Event\n",
    "    trigger_event: Event\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            parent: Workflow,\n",
    "            tools: List[Callable], \n",
    "            system_prompt: str, \n",
    "            trigger_event: Event,\n",
    "            context: Context,\n",
    "            name: str,\n",
    "        ):\n",
    "        self.name = name\n",
    "        self.parent = parent\n",
    "        self.context = context\n",
    "        self.system_prompt = system_prompt\n",
    "        self.context.data[\"redirecting\"] = False\n",
    "        self.trigger_event = trigger_event\n",
    "\n",
    "        def explain_steps(steps:str) -> None:\n",
    "            \"\"\"Explain what you'll do with the request, step by step.\"\"\"\n",
    "            print(Fore.RED + \"[explain_steps] is being executed\" + Style.RESET_ALL)\n",
    "            print(f\"{self.name} will explain steps:\", steps)\n",
    "            context.session.send_event(StopEvent())\n",
    "\n",
    "        def done() -> None:\n",
    "            \"\"\"When you complete your task, call this tool.\"\"\"\n",
    "            print(Fore.RED + \"[done] is being executed\" + Style.RESET_ALL)\n",
    "            print(f\"{self.name} is complete\")\n",
    "            self.context.data[\"redirecting\"] = True\n",
    "            context.session.send_event(ConciergeEvent(just_completed=self.name))\n",
    "\n",
    "        def need_help() -> None:\n",
    "            \"\"\"If the user asks to do something you don't know how to do, call this.\"\"\"\n",
    "            print(Fore.RED + \"[need_help] is being executed\" + Style.RESET_ALL)\n",
    "            print(f\"{self.name} needs help\")\n",
    "            self.context.data[\"redirecting\"] = True\n",
    "            context.session.send_event(StopEvent())\n",
    "\n",
    "        self.tools = [\n",
    "            FunctionTool.from_defaults(fn=done),\n",
    "            FunctionTool.from_defaults(fn=need_help),\n",
    "            FunctionTool.from_defaults(fn=explain_steps),\n",
    "        ]\n",
    "        for t in tools:\n",
    "            self.tools.append(FunctionTool.from_defaults(fn=t))\n",
    "\n",
    "        agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "            self.tools,\n",
    "            llm=self.context.data[\"llm\"],\n",
    "            allow_parallel_tool_calls=False,\n",
    "            system_prompt=self.system_prompt,\n",
    "            verbose=True,\n",
    "        )\n",
    "        self.agent = agent_worker.as_agent()        \n",
    "\n",
    "    async def handle_event(self, ev: Event):\n",
    "        print(Fore.RED + \"[handle_event] is being executed\" + Style.RESET_ALL)\n",
    "        self.current_event = ev\n",
    "\n",
    "        response = str(self.agent.chat(ev.request, chat_history=chat_history))\n",
    "        chat_history.append(ChatMessage(role=MessageRole.ASSISTANT, content=str(response)))\n",
    "        print(\"agent printing!\", self.name)\n",
    "        print(Fore.MAGENTA + str(response) + Style.RESET_ALL)\n",
    "\n",
    "        # send message to user using whatsapp api\n",
    "        #await send_message_to_user(message=str(response), to='5491131500591')\n",
    "\n",
    "        # if they're sending us elsewhere we're done here\n",
    "        if self.context.data[\"redirecting\"]:\n",
    "            self.context.data[\"redirecting\"] = False\n",
    "            return None\n",
    "\n",
    "        # otherwise, get some user input and then loop\n",
    "        user_msg_str = input(\"> \").strip()\n",
    "        chat_history.append(ChatMessage(role=MessageRole.USER, content=user_msg_str))\n",
    "        if user_msg_str == \"\":\n",
    "            return StopEvent()\n",
    "        return self.trigger_event(request=user_msg_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(BaseModel):\n",
    "    ID_PRODUCTO: int = Field(..., strict=True, title=\"Product ID found in the database\")\n",
    "    TIPO: Literal['ESTANDAR', 'INTENSO', 'PIEDRA GRANITO'] = Field(..., title=\"Type of the color, each color has a corresponding type in the database\")\n",
    "    COLOR: str = Field(..., strict=True, title=\"Color of the product (TYPE GOES IN THE OTHER FIELD), in the database it is a foreign key\")\n",
    "    CANTIDAD: int = Field(..., strict=True, title=\"Quantity\")\n",
    "\n",
    "class Order(BaseModel):\n",
    "    ID_CLIENTE: int = Field(..., strict=True, title=\"Customer ID found in the database\")\n",
    "    TIPO_DE_ENTREGA: Literal['CLIENTE', 'RETIRA EN FÁBRICA', 'OTRO']\n",
    "    DIRECCION: Optional[str] = Field(..., strict=True, title=\"Delivery Address, if deliver_type is CLIENTE or RETIRA EN FABRICA is not required, else it is\")\n",
    "    METODO_DE_PAGO: Literal[\"EFECTIVO\", 'DÓLARES', 'MERCADO PAGO', 'CHEQUE', 'TRANSFERENCIA BANCARIA']\n",
    "    NOTA: Optional[str] = Field(None, strict=True, title=\"Note only used if explicitly specified\")\n",
    "    # products: List[Product]\n",
    "\n",
    "class OrderAndProductList(BaseModel):\n",
    "    order: Order\n",
    "    product_list: List[Product]\n",
    "\n",
    "def appsheet_add(rows: List[Dict] | Dict, table_name: str):\n",
    "    print(Fore.RED + \"[appsheet_add] is being executed\" + Style.RESET_ALL)\n",
    "\n",
    "    if isinstance(rows, dict):\n",
    "        rows = [rows]\n",
    "\n",
    "    products_url = f\"https://api.appsheet.com/api/v2/apps/{appsheet_app_id}/tables/{table_name}/Action\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"ApplicationAccessKey\": appsheet_api_key\n",
    "    }\n",
    "\n",
    "    request = {\n",
    "        \"Action\": \"Add\",\n",
    "        \"Properties\": {\"Locale\": \"en-US\"},\n",
    "        \"Rows\": rows\n",
    "    }\n",
    "\n",
    "    response = requests.post(products_url, headers=headers, json=request)\n",
    "    return response\n",
    "\n",
    "def appsheet_edit(rows: List[Dict] | Dict, table_name: str):\n",
    "    print(Fore.RED + \"[appsheet_edit] is being executed\" + Style.RESET_ALL)\n",
    "\n",
    "    if isinstance(rows, dict):\n",
    "        rows = [rows]\n",
    "\n",
    "    products_url = f\"https://api.appsheet.com/api/v2/apps/{appsheet_app_id}/tables/{table_name}/Action\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"ApplicationAccessKey\": appsheet_api_key\n",
    "    }\n",
    "\n",
    "    request = {\n",
    "        \"Action\": \"Edit\",\n",
    "        \"Properties\": {\"Locale\": \"en-US\"},\n",
    "        \"Rows\": rows\n",
    "    }\n",
    "\n",
    "    print(request)\n",
    "\n",
    "    response = requests.post(products_url, headers=headers, json=request)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderWorkflow(Workflow):\n",
    "            \n",
    "    @step(pass_context=True)\n",
    "    async def initialize(self, ctx: Context, ev: InitializeEvent) -> ConciergeEvent:\n",
    "\n",
    "        ctx.data[\"user\"] = {\n",
    "            \"username\": None,\n",
    "            #\"session_token\": None,\n",
    "            #\"account_id\": None,\n",
    "            #\"account_balance\": None,\n",
    "        }\n",
    "        ctx.data[\"success\"] = None\n",
    "        ctx.data[\"redirecting\"] = None\n",
    "        ctx.data[\"overall_request\"] = None\n",
    "        ctx.data[\"order\"] = {}\n",
    "        ctx.data[\"order\"][\"products\"] = []\n",
    "\n",
    "        # Print the contents of ctx.data for debugging\n",
    "        print(\"ctx.data:\", ctx.data)\n",
    "\n",
    "        ctx.data[\"llm\"] = OpenAIIndex(model=\"gpt-4o-mini\",temperature=0)\n",
    "        #ctx.data[\"llm\"] = Anthropic(model=\"claude-3-5-sonnet-20240620\",temperature=0.4)\n",
    "        #ctx.data[\"llm\"] = Anthropic(model=\"claude-3-opus-20240229\",temperature=0.4)\n",
    "        return ConciergeEvent()\n",
    "  \n",
    "    @step(pass_context=True)\n",
    "    async def concierge(self, ctx: Context, ev: ConciergeEvent | StartEvent) -> InitializeEvent | StopEvent | OrchestratorEvent:\n",
    "        \n",
    "        response = None\n",
    "        \n",
    "        # initialize user if not already done\n",
    "        if (\"user\" not in ctx.data):\n",
    "            return InitializeEvent()\n",
    "        \n",
    "        # initialize concierge if not already done\n",
    "        if (\"concierge\" not in ctx.data):\n",
    "            system_prompt = (f\"\"\"\n",
    "                Usa el idioma español (argentina).             \n",
    "                Sos un asistente útil que ayuda a un empleado a manejar el software de su empresa, usa el idioma español (argentina).\n",
    "                Tu trabajo es hacerle preguntas al empleado para entender qué quiere hacer y brindarle las acciones disponibles que puede hacer.\n",
    "                Eso incluye \n",
    "                             * crear un nuevo pedido de productos a un cliente en el sistema\n",
    "                             * crear un nuevo cliente \n",
    "                Cuando el usuario termine con su primer tarea, recuerdale el resto de tareas que podés hacer\n",
    "                             \"\"\")\n",
    "\n",
    "            agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "                tools=[],\n",
    "                llm=ctx.data[\"llm\"],\n",
    "                allow_parallel_tool_calls=False,\n",
    "                system_prompt=system_prompt\n",
    "            )\n",
    "            ctx.data[\"concierge\"] = agent_worker.as_agent()        \n",
    "\n",
    "        concierge = ctx.data[\"concierge\"]\n",
    "        if ctx.data[\"overall_request\"] is not None:\n",
    "            print(\"There's an overall request in progress, it's \", ctx.data[\"overall_request\"])\n",
    "            last_request = ctx.data[\"overall_request\"]\n",
    "            ctx.data[\"overall_request\"] = None\n",
    "            return OrchestratorEvent(request=last_request)\n",
    "        elif (ev.just_completed is not None):\n",
    "            response = concierge.chat(f\"FYI, the user has just completed the task: {ev.just_completed}\")\n",
    "            chat_history.append(ChatMessage(role=MessageRole.ASSISTANT, content=str(response)))\n",
    "        elif (ev.need_help):\n",
    "            print(\"The previous process needs help with \", ev.request)\n",
    "            return OrchestratorEvent(request=ev.request)\n",
    "        elif (ev.request is not None):\n",
    "            response = concierge.chat(ev.request)\n",
    "            chat_history.append(ChatMessage(role=MessageRole.ASSISTANT, content=str(response)))\n",
    "        \n",
    "\n",
    "        if response is not None: \n",
    "            print(\"concierge!!!!\")\n",
    "            print(Fore.MAGENTA + str(response) + Style.RESET_ALL)\n",
    "\n",
    "        # concierge send message to user using whatsapp api \n",
    "        #await send_message_to_user(message=str(response), to='5491131500591')\n",
    "\n",
    "        user_msg_str = input(\"> \").strip()\n",
    "        chat_history.append(ChatMessage(role=MessageRole.USER, content=user_msg_str))\n",
    "        if user_msg_str == \"\":\n",
    "            print(\"User has stopped the system with ''\")\n",
    "            return StopEvent()\n",
    "        #user_msg_str = await user_input.get()\n",
    "        return OrchestratorEvent(request=user_msg_str)\n",
    "    \n",
    "    @step(pass_context=True)\n",
    "    async def orchestrator(self, ctx: Context, ev: OrchestratorEvent) -> ConciergeEvent | OrderCreationEvent | StopEvent | StockManagerEvent:\n",
    "\n",
    "        #print(f\"Orchestrator received request: {ev.request}\")\n",
    "\n",
    "        def emit_order_management() -> bool:\n",
    "            \"\"\"Call this if the user wants create or manage an order in the system.\"\"\"      \n",
    "            print(\"__emitted: order creation\")      \n",
    "            ctx.session.send_event(OrderCreationEvent(request=ev.request))\n",
    "            return True\n",
    "        \n",
    "        def emit_stock_manager() -> bool:\n",
    "            \"\"\"Call this if the user wants to create a new stock movement in the system.\"\"\"\n",
    "            print(\"__emitted: stock manager\")\n",
    "            ctx.session.send_event(StockManagerEvent(request=ev.request))\n",
    "            return True\n",
    "        \n",
    "        \"\"\" def emit_update_order() -> bool:\n",
    "            Call this if the user wants create a new order in the system\n",
    "            print(\"__emitted: order creation\")      \n",
    "            ctx.session.send_event(OrderUpdateEvent(request=ev.request))\n",
    "            return True \"\"\"\n",
    "\n",
    "        def emit_concierge() -> bool:\n",
    "            \"\"\"Call this if the user wants to do something else or you can't figure out what they want to do.\"\"\"\n",
    "            print(\"__emitted: concierge (non stop)\")\n",
    "            #ctx.session.send_event(ConciergeEvent(request=(\"This is the request, the orchestator didn't know how to continue: \"+ev.request)))\n",
    "            #ctx.session.send_event(StopEvent())\n",
    "            self.send_event(ConciergeEvent(request=ev.request))\n",
    "            return True\n",
    "\n",
    "        def emit_stop() -> bool:\n",
    "            \"\"\"Call this if the user wants to stop or exit the system.\"\"\"\n",
    "            print(\"__emitted: stop\")\n",
    "            ctx.session.send_event(StopEvent())\n",
    "            return True\n",
    "        \n",
    "        # define tool for getting customer data\n",
    "        def getCustomerData(customer_name: str) -> str:\n",
    "            \"\"\"Returns the customer metadata from the customer name given by the user to send that value to the system later\"\"\"\n",
    "            print(\"__emitted: getCustomerData\")\n",
    "            test_retriever = vector_index_dict[\"CLIENTES\"].as_retriever(similarity_top_k=1)\n",
    "            nodes =  test_retriever.retrieve(customer_name)\n",
    "            if nodes[0].metadata is None:\n",
    "                print(\"No customer found\")\n",
    "                ctx.session.send_event(StopEvent())\n",
    "            print(f\"For customer {customer_name} found:\", \n",
    "                  nodes[0].metadata[\"CLIENTE\"], nodes[0].metadata[\"ID\"])\n",
    "            return str(nodes[0].metadata)\n",
    "\n",
    "        tools = [\n",
    "            FunctionTool.from_defaults(fn=emit_order_management),\n",
    "            FunctionTool.from_defaults(fn=emit_concierge),\n",
    "            FunctionTool.from_defaults(fn=emit_stop),\n",
    "            FunctionTool.from_defaults(fn=getCustomerData),\n",
    "            FunctionTool.from_defaults(fn=emit_stock_manager),\n",
    "            #FunctionTool.from_defaults(fn=emit_update_order)\n",
    "        ]\n",
    "        \n",
    "        system_prompt = (f\"\"\"\n",
    "            You are on orchestration agent.\n",
    "            Your job is to decide which agent to run based on the current state of the user and what they've asked to do. \n",
    "            You run an agent by calling the appropriate tool for that agent.\n",
    "            in your response, only select the tool, don't add any text into it.      \n",
    "            If there's no clear use for one of the tools, call the tool \"concierge\" to signal that the concierge agent should help, \n",
    "            UNLESS THERE'S AN ERROR, YOU ALWAYS HAVE TO CALL ONE OF THE TOOLS, if you don't call any tool, the system will break.\n",
    "            If you NOTICE SOMETHING IS NOT WORKING or did not call any tools, return the string \"FAILED\" followed by the exact reason you are selecting this option.\n",
    "        \"\"\")\n",
    "\n",
    "        \"\"\"when you call the concierge, also send information to help the concierge answer the user request, as you have more information than him \n",
    "                         (your reply will directly sent to the concierge, the user won't read it).\"\"\"\n",
    "        \n",
    "        agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "            tools=tools,\n",
    "            llm=ctx.data[\"llm\"],\n",
    "            allow_parallel_tool_calls=False,\n",
    "            system_prompt=system_prompt,\n",
    "            verbose=True\n",
    "        )\n",
    "        ctx.data[\"orchestrator\"] = agent_worker.as_agent()        \n",
    "        \n",
    "        orchestrator = ctx.data[\"orchestrator\"]\n",
    "        response = str(orchestrator.chat(ev.request))\n",
    "        print(Fore.MAGENTA + \"Orchestrator: \" +response + Style.RESET_ALL)\n",
    "        chat_history.append(ChatMessage(role=MessageRole.ASSISTANT, content=(\"Información del orquestador: \"+str(response))))\n",
    "\n",
    "        if \"FAILED\" in response:\n",
    "            print(Fore.RED + response + Style.RESET_ALL)\n",
    "            return StopEvent()\n",
    "            #return OrchestratorEvent(request=ev.request)\n",
    "    \n",
    "    @step(pass_context=True)\n",
    "    async def order_manager(self, ctx: Context, ev: OrderCreationEvent) -> ConciergeEvent | StopEvent:\n",
    "\n",
    "        if(\"order_manager_agent\" not in ctx.data):\n",
    "\n",
    "            def send_order():\n",
    "                \"\"\"Useful for sending the order to the system via API request, Order will be stored in the session context. \n",
    "                Make sure to call the other tools to get the IDs before, and that you have all the data needed.\"\"\"\n",
    "\n",
    "                prompt = \"\"\"\n",
    "                You will be provided with data about an order, but you only have to list its products to inser in a database.\n",
    "                Your goal will be to parse the data following the schema provided.\n",
    "                Here is a description of the parameters:\n",
    "                - product: specifies product_id, product type, color, and quantity\n",
    "                - order: general data about the order, and it has a list of products that the user will list\n",
    "                Tell the user the order number id when it's succesfully created\n",
    "\n",
    "                \"\"\"\n",
    "                \n",
    "                response = client.beta.chat.completions.parse(\n",
    "                    model=MODEL,\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": prompt},\n",
    "                        {\"role\": \"user\", \"content\": str(ctx.data[\"order\"])}\n",
    "                    ],\n",
    "                    response_format=OrderAndProductList\n",
    "                )\n",
    "                print(json.loads(response.choices[0].message.content))\n",
    "\n",
    "                products = json.loads(response.choices[0].message.content)[\"product_list\"]\n",
    "                order = json.loads(response.choices[0].message.content)[\"order\"]\n",
    "\n",
    "                response = appsheet_add([order], \"PEDIDOS\")\n",
    "\n",
    "                if isinstance(response, requests.Response) and response.status_code != 200:\n",
    "                    print(f\"Error inserting order: {response.text}\")\n",
    "                    return f\"Error inserting order, stop the system\"\n",
    "                elif response.status_code == 200 and response.json().get('Rows'):\n",
    "\n",
    "                    print(f\"Order inserted successfully, inserting products now\", response.json().get('Rows'))\n",
    "\n",
    "                    order = response.json().get('Rows')[0]\n",
    "\n",
    "                    for product in products:\n",
    "                        product[\"ID_PEDIDO\"] = order[\"ID_KEY\"]\n",
    "\n",
    "                    response = appsheet_add(products, \"PRODUCTOS PEDIDOS\")\n",
    "\n",
    "                    if isinstance(response, requests.Response) and response.status_code != 200:\n",
    "                        print(f\"Error inserting order: {response.text}\")\n",
    "                        return f\"Error inserting products, stop the system\"\n",
    "                    elif response.status_code == 200 and response.json().get('Rows'):\n",
    "\n",
    "                        response = appsheet_edit({\"ID_KEY\": order[\"ID_KEY\"], \"GUARDADO\": 1}, \"PEDIDOS\")\n",
    "                        if isinstance(response, requests.Response) and response.status_code == 200:\n",
    "                            print(f\"Products. Order inserted successfully , Order ID: {order['ID_KEY']}\", response.json().get('Rows'))\n",
    "                            return f\"Order and products created successfully, Order ID: {order['ID_KEY']}\"\n",
    "\n",
    "                        \n",
    "                        else:\n",
    "                            print(f\"Products. Error in the request body or url, check the settings\")\n",
    "                            return f\"Error in the request body or url, check the settings, stop the system\"\n",
    "                    else:\n",
    "                        print(f\"Products. Error in the request body or url, check the settings\")\n",
    "                        return f\"Error in the request body or url, check the settings, stop the system\"\n",
    "      \n",
    "                else:\n",
    "                    print(f\"Order. Error in the request body or url, check the settings\")\n",
    "                    return f\"Error in the request body or url, check the settings, stop the system\"\n",
    "            \n",
    "            def getCustomerID(customer_name: str) -> str:\n",
    "                \"\"\"Returns the customer ID from the customer name given by the user to send that value to the system later\"\"\"\n",
    "                test_retriever = vector_index_dict[\"CLIENTES\"].as_retriever(similarity_top_k=3)\n",
    "                nodes = test_retriever.retrieve(customer_name)\n",
    "\n",
    "                prompt = f\"\"\"\n",
    "                You are part of a complex system that relies on you to get the correct customer ID.\n",
    "                You are given a customer name and a list of possible matches. \n",
    "                Your task is to select the best match based on the name.\n",
    "                Only return the ID of the best match with no quotes, nothing else.\n",
    "                Customer Name: {customer_name}\n",
    "                Matches: {[node.metadata for node in nodes]}\n",
    "                \"\"\"\n",
    "                response = ctx.data[\"llm\"].chat(prompt)\n",
    "                customer_id = response.choices[0].message.content.strip()\n",
    "\n",
    "                # Check if the customer ID matches any of the metadata\n",
    "                for node in nodes:\n",
    "                    if node.metadata[\"ID\"] == customer_id:\n",
    "                        return customer_id\n",
    "\n",
    "                print(\"No matching customer found\")\n",
    "                ctx.session.send_event(StopEvent())\n",
    "                return \"Error: No matching customer found\"\n",
    "            \n",
    "            def createOrder(customer_name:str, payment_method:str, shipment_type_and_info:str, shipment_adress:Optional[str] = \"\", nota:Optional[str] = \"\") -> str:\n",
    "                \"\"\"Creates an order in the session, it will be used to store the order data before sending it to the system. \n",
    "                Don't use it before having the needed data\"\"\"\n",
    "\n",
    "                customer_id = getCustomerID(customer_name)\n",
    "                if customer_id == \"Error: No matching customer found, ask the user for more details about the customer name\": \n",
    "                    return customer_id\n",
    "\n",
    "                ctx.data[\"order\"][\"ID_CLIENTE\"] = customer_id\n",
    "                ctx.data[\"order\"][\"TIPO_DE_ENTREGA\"] = shipment_type_and_info\n",
    "                ctx.data[\"order\"][\"DIRECCION\"] = shipment_adress\n",
    "                ctx.data[\"order\"][\"METODO_DE_PAGO\"] = payment_method\n",
    "                ctx.data[\"order\"][\"NOTA\"] = nota\n",
    "                print(\"Order created:\",  str(ctx.data[\"order\"]))\n",
    "\n",
    "                return \"Order created successfully, make sure to add products before sending it to the system\"\n",
    "            \n",
    "            #DNI/CUIT\n",
    "            def getCustomerCUIT(customer_name: str) -> str:\n",
    "                \"\"\"Returns the CUIT of the customer from the customer name given by the user to send that value to the system later\"\"\"\n",
    "                test_retriever = vector_index_dict[\"CLIENTES\"].as_retriever(similarity_top_k=1)\n",
    "                nodes =  test_retriever.retrieve(customer_name)\n",
    "                print(f\"For customer {customer_name} found:\", \n",
    "                      nodes[0].metadata[\"CLIENTE\"]), nodes[0].metadata[\"DNI/CUIT\"]\n",
    "                if nodes[0].metadata is None:\n",
    "                    print(\"No customer found\")\n",
    "                    ctx.session.send_event(StopEvent())\n",
    "                return nodes[0].metadata[\"DNI/CUIT\"]\n",
    "            \n",
    "            def addProductToOrder(product_name:str, color_description:str, quantity:int):\n",
    "                \"\"\"Adds a product to the order in the current session, product_name is the name of the product (not the color), color description (with its type if the user provided it), and quantity.\n",
    "                Make sure to add all the products using this tool.\"\"\"\n",
    "                \n",
    "                color_tuple = getColorName(color_description)\n",
    "\n",
    "                if color_tuple == \"Error: No matching color found\":\n",
    "                    return \"Error: No matching color found, stop the system, ask the user for more details about the color\"\n",
    "                \n",
    "                product_id = getProductID(product_name)\n",
    "                if product_id == \"Error: No matching product found\":\n",
    "                    return \"Error: No matching product found, stop the system, ask the user for more details about the product\"\n",
    "\n",
    "                product = {\n",
    "                    \"CANTIDAD\": quantity, \n",
    "                    \"ID_PRODUCTO\": product_id, \n",
    "                    \"COLOR\": color_tuple[0], \n",
    "                    \"TIPO\": color_tuple[1]\n",
    "                    }\n",
    "                ctx.data[\"order\"][\"products\"].append(product)\n",
    "                print(f\"Product added to the order: {product}\")\n",
    "\n",
    "                return \"Product added to the order, make sure that all the products are added, and to load other order info too. Don't forget to send it to the system when all the data is loaded\"\n",
    "            \n",
    "            def getProductID(product_description_name: str) -> str:\n",
    "                \"\"\"Returns the product ID from the product name given by the user to send that value to the system later\"\"\"\n",
    "                test_retriever = vector_index_dict[\"PRODUCTOS\"].as_retriever(similarity_top_k=3)\n",
    "                nodes = test_retriever.retrieve(product_description_name)\n",
    "\n",
    "                prompt = f\"\"\"\n",
    "                You are part of a complex system that relies on you to get the correct product ID.\n",
    "                You are given a product description and a list of possible matches. \n",
    "                Your task is to select the best match based on the description.\n",
    "                Only return the ID of the best match with no quotes, nothing else.\n",
    "                Product Description: {product_description_name}\n",
    "                Matches: {[node.metadata for node in nodes]}\n",
    "                \"\"\"\n",
    "                response = ctx.data[\"llm\"].chat(prompt)\n",
    "                product_id = response.choices[0].message.content.strip()\n",
    "\n",
    "                # Check if the product ID matches any of the metadata\n",
    "                for node in nodes:\n",
    "                    if node.metadata[\"ID\"] == product_id:\n",
    "                        return product_id\n",
    "\n",
    "                print(\"No matching product found\")\n",
    "                ctx.session.send_event(StopEvent())\n",
    "                return \"Error: No matching product found\"\n",
    "            \n",
    "            def getColorName(color_description: str) -> Tuple[str, str]:\n",
    "                \"\"\"Returns the top 3 search for the Color exact name with its corresponding type from the color given by the user to send that value to the system later,\n",
    "                based on the color description given by the user, choose the correct one\"\"\"\n",
    "                test_retriever = vector_index_dict[\"COLORES\"].as_retriever(similarity_top_k=3)\n",
    "                nodes = test_retriever.retrieve(color_description)\n",
    "\n",
    "                prompt = f\"\"\"\n",
    "                You are part of a complex system that relies on you to get the correct color and type for the products.\n",
    "                You are given a description of a color and a list of possible matches. \n",
    "                Your task is to select the best match based on the description.\n",
    "                Only return the COLOR and TIPO of the best match with the format \"COLOR, TIPO\" with no quotes, nothing else.\n",
    "                Description: {color_description}\n",
    "                Matches: {[node.metadata for node in nodes]}\n",
    "                \"\"\"\n",
    "                response = ctx.data[\"llm\"].chat(prompt)\n",
    "                color_info = response.choices[0].message.content.strip().split(\", \")\n",
    "\n",
    "                # Check if the color info matches any of the metadata\n",
    "                for node in nodes:\n",
    "                    if node.metadata[\"COLOR\"] == color_info[0] and node.metadata[\"TIPO\"] == color_info[1]:\n",
    "                        return color_info[0], color_info[1]\n",
    "\n",
    "                print(\"No matching color found\")\n",
    "                ctx.session.send_event(StopEvent())\n",
    "                return \"Error: No matching color found\"\n",
    "        \n",
    "            def udpate_order(order_id:int, new_status:str) -> str:\n",
    "                \"\"\"Updates the status of an order in the system, given its ID (as int) (or sometimes referenced as number of order, pedido o remito) and the new status\n",
    "                Available statuses are: 'ANULADO' 'En expreso' 'En viaje' 'Listo para despachar' 'Nuevo pedido' 'Pedido tomado' 'Pidiendo' 'Recibido'\"\"\"\n",
    "\n",
    "                if new_status not in ['ANULADO', 'En expreso', 'En viaje', 'Listo para despachar', 'Nuevo pedido', 'Pedido tomado', 'Pidiendo', 'Recibido']:\n",
    "                    return \"Invalid status, check the available statuses\"\n",
    "                \n",
    "                # get all rows from table\n",
    "                with engine.connect() as conn:\n",
    "\n",
    "                    columns_query=(\n",
    "                        f\"SELECT ID_KEY FROM PEDIDOS WHERE ID = '{order_id}'\"\n",
    "                    )\n",
    "\n",
    "                    cursor = conn.execute(text(columns_query))\n",
    "                    result = cursor.fetchall()\n",
    "                    if len(result) != 1:\n",
    "                        print(f\"Error: Expected one row, but got {len(result)} rows\")\n",
    "                        return f\"Error: Expected one row, but got {len(result)} rows\"\n",
    "                    \n",
    "                    id_key = result[0][0]\n",
    "\n",
    "                products_url = f\"https://api.appsheet.com/api/v2/apps/{appsheet_app_id}/tables/PEDIDOS/Action\"\n",
    "\n",
    "                headers = {\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                    \"ApplicationAccessKey\": appsheet_api_key\n",
    "                }\n",
    "\n",
    "                request = {\n",
    "                    \"Action\": \"Edit\",\n",
    "                    \"Properties\": {\"Locale\": \"en-US\"},\n",
    "                    \"Rows\": [\n",
    "                        {\n",
    "                            \"ID_KEY\": id_key,\n",
    "                            \"ESTADO\": new_status\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "\n",
    "                print(request)\n",
    "\n",
    "                response = requests.post(products_url, headers=headers, json=request)\n",
    "\n",
    "                if isinstance(response, requests.Response) and response.status_code != 200:\n",
    "                    print(f\"Error updateing order: {response.text}\")\n",
    "                    return f\"Error updating order, stop the system\"\n",
    "                elif response.status_code == 200 and response.json().get('Rows'):\n",
    "\n",
    "                    print(f\"Order updated successfully\")\n",
    "                    return \"Order updated successfully\"\n",
    "                else:\n",
    "                    print(f\"Order. Error in the request body or url, check the settings\")\n",
    "                    return f\"Error in the request body or url, check the settings, stop the system\"\n",
    "                            \n",
    "                \n",
    "            \n",
    "            def stop() -> None:\n",
    "                \"\"\"Call this if you notice that something is not working propperly.\"\"\"\n",
    "                print(\"Order creator agent is stopping\")\n",
    "                ctx.session.send_event(StopEvent())     \n",
    "            \n",
    "            system_prompt = (f\"\"\"\n",
    "                \n",
    "                Usa el idioma español (argentina).\n",
    "                You are a helpful assistant that recollects data to create an order correctly in the system by sending an API request.\n",
    "                This is the ORDER structure:\n",
    "                            {str(Product)}\n",
    "                            {str(Order)}\n",
    "                \n",
    "                You should use the \"createOrder\" and \"addProductToOrder\" for all the products to correctly create the order. \n",
    "                    \n",
    "                Once you have loaded all the data, call the \"send_order\" tool and it will send the order to the system taken the data you have just loaded.\n",
    "                if you don't send the order, you'll break the system\n",
    "                \"\"\")\n",
    "             \n",
    "            ctx.data[\"order_manager_agent\"] = ConciergeAgent(\n",
    "                name=\"Order Manager Agent\",\n",
    "                parent=self,\n",
    "                tools=[send_order, stop, addProductToOrder, createOrder, getCustomerCUIT, getProductID, getColorName, udpate_order],\n",
    "                context=ctx,\n",
    "                system_prompt=system_prompt,\n",
    "                trigger_event=OrderCreationEvent\n",
    "            )\n",
    "\n",
    "        return await ctx.data[\"order_manager_agent\"].handle_event(ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def stock_manager(self, ctx: Context, ev: StockManagerEvent) -> ConciergeEvent | StopEvent:\n",
    "        if \"stock_manager_agent\" not in ctx.data:\n",
    "            # Define function to create a stock movement\n",
    "            def create_stock_movement(product_description: str, quantity: int) -> str:\n",
    "                \"\"\"Creates a stock movement in the STOCK table.\"\"\"\n",
    "                \n",
    "                # Retrieve the product ID based on the product description\n",
    "                test_retriever = vector_index_dict[\"PRODUCTOS\"].as_retriever(similarity_top_k=3)\n",
    "                nodes = test_retriever.retrieve(product_description)\n",
    "\n",
    "                prompt = f\"\"\"\n",
    "                You are part of a complex system that relies on you to get the correct product ID.\n",
    "                You are given a product description and a list of possible matches. \n",
    "                Your task is to select the best match based on the description.\n",
    "                Only return the ID of the best match with no quotes, nothing else.\n",
    "                Product Description: {product_description}\n",
    "                Matches: {[node.metadata for node in nodes]}\n",
    "                \"\"\"\n",
    "                response = ctx.data[\"llm\"].chat(prompt)\n",
    "                product_id = response.choices[0].message.content.strip()\n",
    "\n",
    "                # Check if the product ID matches any of the metadata\n",
    "                for node in nodes:\n",
    "                    if node.metadata[\"ID\"] == product_id:\n",
    "                        stock_movement = {\n",
    "                            \"ID PRODUCTO\": product_id,\n",
    "                            \"CANTIDAD\": quantity\n",
    "                        }\n",
    "                        response = appsheet_add([stock_movement], \"STOCK\")\n",
    "                        if response.status_code == 200:\n",
    "                            return \"Stock movement created successfully.\"\n",
    "                        else:\n",
    "                            return f\"Error creating stock movement: {response.text}\"\n",
    "\n",
    "                print(\"No matching product found\")\n",
    "                ctx.session.send_event(StopEvent())\n",
    "                return \"Error: No matching product found, ask the user for more details about the product\"\n",
    "            \n",
    "            def getProductID(product_description_name: str) -> str:\n",
    "                \"\"\"Returns the product ID from the product name given by the user to send that value to the system later\"\"\"\n",
    "                test_retriever = vector_index_dict[\"PRODUCTOS\"].as_retriever(similarity_top_k=3)\n",
    "                nodes = test_retriever.retrieve(product_description_name)\n",
    "\n",
    "                prompt = f\"\"\"\n",
    "                You are part of a complex system that relies on you to get the correct product ID.\n",
    "                You are given a product description and a list of possible matches. \n",
    "                Your task is to select the best match based on the description.\n",
    "                Only return the ID of the best match with no quotes, nothing else.\n",
    "                Product Description: {product_description_name}\n",
    "                Matches: {[node.metadata for node in nodes]}\n",
    "                \"\"\"\n",
    "                response = ctx.data[\"llm\"].chat(prompt)\n",
    "                product_id = response.choices[0].message.content.strip()\n",
    "\n",
    "                # Check if the product ID matches any of the metadata\n",
    "                for node in nodes:\n",
    "                    if node.metadata[\"ID\"] == product_id:\n",
    "                        return product_id\n",
    "\n",
    "                print(\"No matching product found\")\n",
    "                ctx.session.send_event(StopEvent())\n",
    "                return \"Error: No matching product found\"\n",
    "            \n",
    "            \n",
    "            def stop() -> None:\n",
    "                \"\"\"Call this if you notice that something is not working propperly.\"\"\"\n",
    "                print(\"Stock manager agent is stopping\")\n",
    "                ctx.session.send_event(StopEvent())\n",
    "\n",
    "            # Define tools for the agent\n",
    "            tools = [\n",
    "                FunctionTool.from_defaults(fn=create_stock_movement),\n",
    "                FunctionTool.from_defaults(fn=stop),\n",
    "            ]\n",
    "\n",
    "            # Define system prompt for the agent\n",
    "            system_prompt = \"You are a stock manager agent responsible for creating stock movements in the system.\"\n",
    "\n",
    "            # Initialize the agent\n",
    "            agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "                tools=tools,\n",
    "                llm=ctx.data[\"llm\"],\n",
    "                allow_parallel_tool_calls=False,\n",
    "                system_prompt=system_prompt,\n",
    "                verbose=True\n",
    "            )\n",
    "            ctx.data[\"stock_manager_agent\"] = agent_worker.as_agent()\n",
    "\n",
    "        # Get the agent from context\n",
    "        stock_manager_agent = ctx.data[\"stock_manager_agent\"]\n",
    "        response = stock_manager_agent.chat(ev.request)\n",
    "        print(Fore.MAGENTA + str(response) + Style.RESET_ALL)\n",
    "        chat_history.append(ChatMessage(role=MessageRole.ASSISTANT, content=str(response)))\n",
    "\n",
    "        # Get user input and continue or stop\n",
    "        user_msg_str = input(\"> \").strip()\n",
    "        if user_msg_str == \"\":\n",
    "            return StopEvent()\n",
    "        return StockManagerEvent(request=user_msg_str)\n",
    "\n",
    "\n",
    "#draw_all_possible_flows(OrderWorkflow,filename=\"order_workflow.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_all_possible_flows(OrderWorkflow,filename=\"order_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hola, quisiera agregar un pedido de 12 'RM de 30  LINEA NORT' color eucalipto estandar,  4 FONDO BASE de 20 linea nort color neutro estandar para jorge que va a retirar en fábrica y pagar en efectivo\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hola, quisiera agregar un pedido de 12 'RM de 30  LINEA NORT' color eucalipto estandar para jorge que va a retirar en fábrica y pagar en efectivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for every function, add a log printing with Fore.RED saying '[function_name] is being executed' so its easy to understand the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agrega 23 al stock de rm de 30 linea nort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step concierge\n",
      "Step concierge produced event InitializeEvent\n",
      "Running step initialize\n",
      "ctx.data: {'user': {'username': None}, 'success': None, 'redirecting': None, 'overall_request': None, 'order': {'products': []}}\n",
      "Step initialize produced event ConciergeEvent\n",
      "Running step concierge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step concierge produced event OrchestratorEvent\n",
      "Running step orchestrator\n",
      "Added user message to memory: agrega 23 al stock de rm de 30 linea nort\n",
      "=== Calling Function ===\n",
      "Calling function: emit_stock_manager with args: {}\n",
      "__emitted: stock manager\n",
      "=== Function Output ===\n",
      "True\n",
      "\u001b[35mOrchestrator: \u001b[0m\n",
      "Step orchestrator produced no event\n",
      "Running step stock_manager\n",
      "Added user message to memory: agrega 23 al stock de rm de 30 linea nort\n",
      "=== Calling Function ===\n",
      "Calling function: create_stock_movement with args: {\"product_description\": \"rm de 30 linea nort\", \"quantity\": 23}\n",
      "=== Function Output ===\n",
      "Encountered error: 1 validation error for LLMChatStartEvent\n",
      "messages\n",
      "  Input should be a valid list [type=list_type, input_value=\"\\n                You ar...AL'}]\\n                \", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/list_type\n",
      "=== Calling Function ===\n",
      "Calling function: create_stock_movement with args: {\"product_description\": \"rm de 30 linea nort\", \"quantity\": 23}\n",
      "=== Function Output ===\n",
      "Encountered error: 1 validation error for LLMChatStartEvent\n",
      "messages\n",
      "  Input should be a valid list [type=list_type, input_value=\"\\n                You ar...AL'}]\\n                \", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.8/v/list_type\n",
      "=== Calling Function ===\n",
      "Calling function: stop with args: {}\n",
      "Stock manager agent is stopping\n",
      "=== Function Output ===\n",
      "None\n",
      "=== LLM Response ===\n",
      "Parece que hubo un problema al intentar agregar el stock. Estoy revisando la situación. ¿Te gustaría que lo intentara de nuevo o necesitas ayuda con algo más?\n",
      "\u001b[35mParece que hubo un problema al intentar agregar el stock. Estoy revisando la situación. ¿Te gustaría que lo intentara de nuevo o necesitas ayuda con algo más?\u001b[0m\n",
      "Step stock_manager produced event StopEvent\n",
      "<llama_index.core.workflow.session.WorkflowSession object at 0x7fb3f1cca590>\n"
     ]
    }
   ],
   "source": [
    "c = OrderWorkflow(timeout=500, verbose=True)\n",
    "result = await c.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import gradio as gr\\nimport os\\nfrom openai import OpenAI\\nimport assemblyai as aai\\nfrom tempfile import NamedTemporaryFile\\nfrom dotenv import load_dotenv\\n\\n# Load API keys from environment variables\\nload_dotenv()\\naai.settings.api_key = os.getenv(\"ASSEMBLYAI_API_KEY\")\\ntranscriber = aai.Transcriber()\\n\\n# Test OpenAI TTS\\ndef test_tts(test_text):\\n    #test_text = \"Saucotec is gonna take over the world.\"\\n    speech_file_path = \"test.mp3\"  # NamedTemporaryFile(suffix=\".mp3\", delete=False).name\\n\\n    try:\\n        response = client.audio.speech.create(\\n            model=\"tts-1\",  # Make sure you have access to the TTS model\\n            voice=\"onyx\",  # Ensure the voice exists\\n            input=test_text\\n        )\\n        response.stream_to_file(speech_file_path)\\n        #print(f\"Audio saved to {speech_file_path}\")\\n        return response\\n    except Exception as e:\\n        print(f\"Error generating audio: {e}\")\\n\\n# Test AssemblyAI transcription\\nasync def transcribe(audio_file_path):\\n    config = aai.TranscriptionConfig(speaker_labels=True, language_code=\"es\")\\n\\n    try:\\n        transcript = transcriber.transcribe(audio_file_path, config)\\n\\n        if transcript.status == aai.TranscriptStatus.completed:\\n            print(f\"Transcription: {transcript.text}\")\\n            result = await c.run(\\n            message= transcript.text\\n            #\"hola, quisiera agregar un pedido de 12 \\'RM de 30  LINEA NORT\\' color eucalipto estandar para jorge que va a retirar en fábrica y pagar en efectivo\"\\n            #transcript.text\\n            )\\n            print(\"Finalizado:\", main_response)\\n            test_tts(main_response)\\n            print(\"Audio generado\")\\n            with open(\"test.mp3\", \"rb\") as audio_file:\\n                audio_data = audio_file.read()\\n            return audio_data\\n        \\n    except Exception as e:\\n        print(f\"Error transcribing audio: {e}\")\\n\\n# Create the Gradio interface\\n# Removed the \\'source\\' parameter from gr.Audio\\nui = gr.Interface(fn=transcribe, inputs=gr.Audio(type=\"filepath\"), outputs=\"audio\", live=True)\\n\\n# Launch the interface and share it publicly\\nui.launch(share=True)\\n '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import gradio as gr\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import assemblyai as aai\n",
    "from tempfile import NamedTemporaryFile\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from environment variables\n",
    "load_dotenv()\n",
    "aai.settings.api_key = os.getenv(\"ASSEMBLYAI_API_KEY\")\n",
    "transcriber = aai.Transcriber()\n",
    "\n",
    "# Test OpenAI TTS\n",
    "def test_tts(test_text):\n",
    "    #test_text = \"Saucotec is gonna take over the world.\"\n",
    "    speech_file_path = \"test.mp3\"  # NamedTemporaryFile(suffix=\".mp3\", delete=False).name\n",
    "\n",
    "    try:\n",
    "        response = client.audio.speech.create(\n",
    "            model=\"tts-1\",  # Make sure you have access to the TTS model\n",
    "            voice=\"onyx\",  # Ensure the voice exists\n",
    "            input=test_text\n",
    "        )\n",
    "        response.stream_to_file(speech_file_path)\n",
    "        #print(f\"Audio saved to {speech_file_path}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating audio: {e}\")\n",
    "\n",
    "# Test AssemblyAI transcription\n",
    "async def transcribe(audio_file_path):\n",
    "    config = aai.TranscriptionConfig(speaker_labels=True, language_code=\"es\")\n",
    "\n",
    "    try:\n",
    "        transcript = transcriber.transcribe(audio_file_path, config)\n",
    "\n",
    "        if transcript.status == aai.TranscriptStatus.completed:\n",
    "            print(f\"Transcription: {transcript.text}\")\n",
    "            result = await c.run(\n",
    "            message= transcript.text\n",
    "            #\"hola, quisiera agregar un pedido de 12 'RM de 30  LINEA NORT' color eucalipto estandar para jorge que va a retirar en fábrica y pagar en efectivo\"\n",
    "            #transcript.text\n",
    "            )\n",
    "            print(\"Finalizado:\", main_response)\n",
    "            test_tts(main_response)\n",
    "            print(\"Audio generado\")\n",
    "            with open(\"test.mp3\", \"rb\") as audio_file:\n",
    "                audio_data = audio_file.read()\n",
    "            return audio_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "\n",
    "# Create the Gradio interface\n",
    "# Removed the 'source' parameter from gr.Audio\n",
    "ui = gr.Interface(fn=transcribe, inputs=gr.Audio(type=\"filepath\"), outputs=\"audio\", live=True)\n",
    "\n",
    "# Launch the interface and share it publicly\n",
    "ui.launch(share=True)\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
